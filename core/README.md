---

# ğŸ“‚ `core/` â€“ OTC Ops Copilot Core Logic

The `core/` folder contains the **brains of OTC Ops Copilot**.
This is where natural language queries are turned into **SQL queries**, validated, executed against the MS SQL database, and visualized for the user.

---

## ğŸ“Œ Files & Responsibilities

### ğŸ”¹ `engine.py`

* **Main orchestrator** for the full NL â†’ SQL â†’ Execution pipeline.
* Steps:

  1. Get **context** from retriever (`ChromaDB`, `Weaviate`, or `GraphDB`).
  2. Generate SQL with LLM (`sql_generator.py`).
  3. Validate SQL (`sql_validator.py`).
  4. Run SQL against MS SQL (`db_connector.py`).
  5. Return both the **SQL** and the **results**.

---

### ğŸ”¹ `retriever.py`

* Acts as a **factory** to select the retriever backend:

  * **ChromaDB** â†’ lightweight, local embeddings DB.
  * **Weaviate** â†’ enterprise vector DB, integrates with in-house LLM.
  * **Graph (Neo4j)** â†’ schema-aware retrieval (best for complex joins).
* Exposes a single method:

  ```python
  query(question, top_k=5)
  ```
* Keeps the **UI/backend decoupled** from specific database technologies.

---

### ğŸ”¹ `sql_generator.py`

* Calls an **LLM** (your in-house model, or external for POC) to convert:

  ```
  (Natural Language Question + Retrieved Context) â†’ SQL
  ```
* Example:

  ```python
  sql = generate_sql("Show confirmed trades today", context)
  ```
* Designed to work with:

  * Internal LLM API (`http://inhouse-llm/api/v1/generate`)
  * Or external fallback (e.g., Gemini, OpenAI) for demo purposes.

---

### ğŸ”¹ `sql_validator.py`

* Ensures **safety & correctness** of generated SQL:

  * Must start with `SELECT`.
  * No destructive operations (`INSERT`, `UPDATE`, `DELETE`, `DROP`, etc.).
  * Basic structure check (ensures `FROM` exists).
* Prevents accidental data corruption.
* Returns `True/False` on validation.

---

### ğŸ”¹ `db_connector.py`

* Handles connection to **MS SQL Server** (read-only).
* Reads DB credentials from `config/db_config.yaml`.
* Provides:

  * `get_connection()` â†’ opens DB connection.
  * `run_query(sql)` â†’ executes a query and returns a Pandas DataFrame.

âš ï¸ **Read-only enforcement** is strongly recommended (DB user should not have write privileges).

---

### ğŸ”¹ `visualizer.py`

* Uses **Plotly** to generate visualizations.
* Logic:

  * If multiple numeric columns â†’ `bar chart`.
  * If single numeric column â†’ `histogram`.
* Returns a chart object that Streamlit can display.

---

## ğŸ“Œ Flow of Control

1. User enters NL question in UI (`app/app.py`).
2. `engine.ask()` pipeline runs:

   * Retriever fetches **schema/rules context**.
   * LLM generates SQL.
   * SQL is validated.
   * Query executed in MS SQL.
   * Results + visualization returned.
3. UI shows **SQL + results table + charts**.

---

## ğŸ“Œ Backend Selection

* **ChromaDB** â†’ POC / local lightweight usage.
* **Weaviate** â†’ Enterprise use, integrates with in-house LLM.
* **GraphDB (Neo4j)** â†’ Handles **complex joins, relationships**, useful for OTC trade confirmation schema.

---

âœ… In short:
The **`core/` folder = logic & intelligence layer**, separating user-facing UI (`app/`) from database + LLM interactions.

---
